{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次实验要求我们从给定的数据中挖掘出所有最小函数依赖，数据在文件data.txt中，12个属性，共14970条记录。\n",
    "\n",
    "我采取的算法为TANE/MEM算法，详细算法见下图(图截自宋老师的课件)：\n",
    "![algorithm](algorithm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "t1 = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们需要定义一个函数来获得partition，这是TANE算法的核心所在。\n",
    "\n",
    "在本次实验中，属性集（attributes）的类型为元素类型为number的集合（由于python中set不是hashable的，故使用frozenset来表示集合，下同），而partition使用集合的集合来表示。\n",
    "\n",
    "在函数get_partition中，为了防止重复计算，因此采用记忆化搜索的方式，将结果储存在partitions中（partitions是一个从属性集到划分的一个map）。因此在函数头部首先检查是否已经计算过该值，若计算过则直接返回储存好的值，否则分类讨论：\n",
    "* 属性集长度为0，则代表不使用任何属性来进行划分，因此返回空集。\n",
    "* 属性集长度为1，则该属性将作为划分依据，使用一个map聚合在该划分依据下的等价类，这些等价类构成的集合即为所求的结果。\n",
    "* 属性集长度大于等于2（设长度为l），可以利用之前的划分结果得到当前划分结果。具体实现方式为：\n",
    "    1. 获得当前属性集的任意两个不同的长度为l-1的属性子集对应的那两个划分。\n",
    "    2. 对这两个划分求积即为所需结果，详细过程见函数merge_partition。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partitions = {}\n",
    "def getFrozenSetFromOne(x):\n",
    "    return frozenset([x,])\n",
    "\n",
    "def merge_partition(ps1, ps2):\n",
    "    s = []\n",
    "    iRow2p = {}\n",
    "    for i, p1 in enumerate(ps1):\n",
    "        for iRow in p1:\n",
    "            iRow2p[iRow] = i\n",
    "    for p2 in ps2:\n",
    "        tmp = defaultdict(list)\n",
    "        for iRow in p2:\n",
    "            tmp[iRow2p[iRow]].append(iRow)\n",
    "        s += tmp.values()\n",
    "    return s\n",
    "\n",
    "def get_partition(attributes):\n",
    "    if attributes in partitions:\n",
    "        return partitions[attributes]\n",
    "    \n",
    "    if len(attributes) == 0:\n",
    "        partitions[attributes] = []\n",
    "    elif len(attributes) == 1:\n",
    "        iAttr = tuple(attributes)[0]\n",
    "        d = defaultdict(list)\n",
    "        for index, row in enumerate(table):\n",
    "            d[row[iAttr]].append(index)\n",
    "        partitions[attributes] = d.values()\n",
    "    else:\n",
    "        attr_tuple = tuple(attributes)\n",
    "        ps1 = get_partition(frozenset(attr_tuple[0:-1]))\n",
    "        ps2 = get_partition(frozenset(attr_tuple[0:-2] + attr_tuple[-1:]))\n",
    "        partitions[attributes] = merge_partition(ps1, ps2)\n",
    "        \n",
    "    return partitions[attributes]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了获得划分的函数，判定两个属性集之间是否存在函数依赖就变得简单了，只需判定这两个属性集对应的划分长度是否相同即可。详见函数`isValid`，该函数判定X-{E} -> E是否是一个合法的函数依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isValid(X, E): \n",
    "    '''\n",
    "    test if X\\{E} -> E is valid\n",
    "    X is a set of number, E is a number\n",
    "    '''\n",
    "    return len(get_partition(X - {E})) == len(get_partition(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们开始考虑每一层的计算，按照TANE算法的流程，对于$L_l$中的所有元素X，我们首先计算出$\\cap_{E \\in X} RHS^{+}(X - \\{E\\})$并将该集合赋给$RHS^{+}(X)$，然后遍历$X \\cap RHS^{+}(X)$中的所有元素，判定$X - \\{E\\} \\rightarrow E$ 是否是一个合法的函数依赖，若是，保存该函数依赖，从$RHS^{+}(X )$中去除E和$R - X$中的所有元素。最后判定$RHS^{+}(X )$是否是一个空集，若是，则从$L_l$中删除X即可。\n",
    "\n",
    "算法实现见函数`compute_dependencies`，参数L即为$L_l$，L_new储存删除后的$L_l$。（这里需要注意的是在将L拷贝给L_new时，由于python中的直接赋值为浅拷贝，修改L_new会同步修改L，造成程序运行结果错误，因此应该使用L.copy()来进行深拷贝）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_dependencies(L): # L is a set of tuple of number\n",
    "    L_new = L.copy()\n",
    "    for X in L:\n",
    "        Xs = frozenset(X)\n",
    "        RHS[X] = R\n",
    "        for E in Xs:\n",
    "            RHS[X] = RHS[X] & RHS[Xs - {E}]\n",
    "        for E in RHS[X] & Xs:\n",
    "            if isValid(Xs, E):\n",
    "                fds.append((Xs - {E}, E))\n",
    "                RHS[X] -= getFrozenSetFromOne(E)\n",
    "                RHS[X] = RHS[X] & Xs\n",
    "        if len(RHS[X]) == 0:\n",
    "            L_new.remove(X)\n",
    "    \n",
    "    return L_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的函数赋值由上一层的candidate key生成下一层的candidate key。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_next_level(L):\n",
    "    # list comprehension?\n",
    "    Ln = set([])\n",
    "    for l1 in L:\n",
    "        for l2 in L:\n",
    "            if l1 != l2 and len(l1 - l2) == 1:\n",
    "                Ln.add(l1 | l2)\n",
    "    return Ln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于结果要求按照字典序进行排序，因此需要自定义排序函数，首先按照函数依赖的左边进行排序，在左边相同的情况下按照右边进行排序。\n",
    "\n",
    "结果输出部分较为简单，对结果进行自定义排序后按照题目要求的格式输出到文件即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mycmp(fd1, fd2):\n",
    "    left1 = sorted(list(fd1[0]))\n",
    "    left2 = sorted(list(fd2[0]))\n",
    "    if left1 < left2 or (fd1[0] == fd2[0] and fd1[1] < fd2[1]):\n",
    "        return -1\n",
    "    elif left1 > left2 or (fd1[0] == fd2[0] and fd1[1] > fd2[1]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def output_fd(fds):\n",
    "    with open(output_filename, 'w') as f:\n",
    "        fds_sorted = sorted(fds, cmp=mycmp)\n",
    "        for fd in fds_sorted:\n",
    "            str = ''\n",
    "            for l in sorted(list(fd[0])):\n",
    "                str += '%d ' % (l+1)\n",
    "            str += '-> %d\\n' % (fd[1]+1)\n",
    "            f.write(str)\n",
    "            # print(str, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了上面的铺垫，函数主体部分就比较简单了，首先读入文件，然后从第1层开始逐层计算函数依赖，最后输出结果即可。具体实现详见下面的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: 2, time used: 0:00:07.504743\n",
      "level: 3, time used: 0:00:13.684483\n",
      "level: 4, time used: 0:00:29.408593\n",
      "level: 5, time used: 0:00:39.931784\n",
      "level: 6, time used: 0:00:42.548781\n",
      "level: 7, time used: 0:00:42.550652\n",
      "level: 8, time used: 0:00:42.550925\n",
      "level: 9, time used: 0:00:42.551150\n",
      "level: 10, time used: 0:00:42.551279\n",
      "level: 11, time used: 0:00:42.551358\n",
      "level: 12, time used: 0:00:42.551474\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "input_filename = 'data.txt'\n",
    "output_filename = 'output.txt'\n",
    "with open(input_filename, 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    table = map(tuple, reader)\n",
    "\n",
    "maxL = len(table[0])\n",
    "R = frozenset(range(maxL))\n",
    "RHS = {frozenset([]): R}\n",
    "fds = []\n",
    " \n",
    "L = frozenset(map(getFrozenSetFromOne, R))\n",
    "L = compute_dependencies(L)\n",
    "for i in range(1, maxL):\n",
    "    L = compute_dependencies(generate_next_level(L))\n",
    "    print('level: %d, time used: %s' %(i+1, datetime.now() - t1))\n",
    "\n",
    "output_fd(fds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是一些与函数依赖挖掘无关的啰嗦。\n",
    "\n",
    "我的第一版实现花了一个半小时才跑出所有结果，经过一早上的优化，终于可以在40s左右跑完了。在调试过程中，我体会到了jupyter notebook的强大，只需要一句%prun即可测试出整段python代码的运行时间分布，大大方便了我找出瓶颈。下面是我在优化过程中做的一个实验，我定义了4个函数，这4个函数的目的都是一样的，返回一个元素类型为frozenset的frozenset（由于set是unhashable的，不能作为map的键，也不能作为set的元素。而frozenset是hashable的，故本次试验大量使用了frozenset）。\n",
    "\n",
    "第一个函数直接通过frozenset的或运算来实现，第二个通过list[tuple]来实现，第三个通过list[list]来实现，最后转化成目标格式，第四个通过set[set]来实现。\n",
    "\n",
    "从运行时间来看，这四种方式的运行时间逐渐降低，最快的方法比最慢的方法快了100余倍。直接使用frozenset效率低下有如下两个原因：\n",
    "1. frozenset是不可变的，当需要修改其内容时需要重新分配空间，故时间效率很低。\n",
    "2. 由于元素天生是不重复的（每次插入c时c的值都会增加1，保证了c的不重复），故每次将c插入cur时检查cur中是否有元素与c是否重复是多余的。\n",
    "而set，list是可变的，当发生大量修改时效率较高。\n",
    "\n",
    "而我的第一版程序使用的就是最慢的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 7.6 s per loop\n",
      "10 loops, best of 3: 147 ms per loop\n",
      "10 loops, best of 3: 94.4 ms per loop\n",
      "10 loops, best of 3: 66.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "n = 15000\n",
    "m = 12\n",
    "def get_frozenset():\n",
    "    c = 0\n",
    "    s1 = frozenset([])\n",
    "    for i in range(n):\n",
    "        cur = frozenset([])\n",
    "        for j in range(m):\n",
    "            c += 1\n",
    "            cur |= frozenset([c])\n",
    "        s1 |= frozenset([cur])\n",
    "    return s1\n",
    "  \n",
    "def get_tuple():\n",
    "    c = 0\n",
    "    s1 = []\n",
    "    for i in range(n):\n",
    "        cur = ()\n",
    "        for j in range(m):\n",
    "            c += 1\n",
    "            cur += (c,)\n",
    "        s1.append(cur)\n",
    "    s1 = frozenset(map(frozenset, s1))\n",
    "    return s1\n",
    "\n",
    "def get_list():\n",
    "    c = 0\n",
    "    s1 = []\n",
    "    for i in range(n):\n",
    "        cur = []\n",
    "        for j in range(m):\n",
    "            c += 1\n",
    "            cur.append(c)\n",
    "        s1.append(cur)\n",
    "    s1 = frozenset(map(frozenset, s1))\n",
    "    return s1\n",
    "\n",
    "def get_set():\n",
    "    c = 0\n",
    "    s1 = set([])\n",
    "    for i in range(n):\n",
    "        cur = set([])\n",
    "        for j in range(m):\n",
    "            c += 1\n",
    "            cur.add(c)\n",
    "        s1.add(frozenset(cur))\n",
    "    return frozenset(s1)\n",
    "\n",
    "assert(get_frozenset() == get_list_set() and get_list_set() == get_list() and get_list() == get_set())\n",
    "\n",
    "%timeit get_frozenset()\n",
    "%timeit get_list_set()\n",
    "%timeit get_list()\n",
    "%timeit get_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
